import * as sdk from 'microsoft-cognitiveservices-speech-sdk';
import { logger } from '../utils/logger';

// Configuration Azure Speech Services (r√©gion EU pour conformit√© RGPD)
const AZURE_SPEECH_KEY = import.meta.env.VITE_AZURE_SPEECH_KEY;
const AZURE_SPEECH_REGION = import.meta.env.VITE_AZURE_SPEECH_REGION || 'westeurope';
const AZURE_SPEECH_ENDPOINT = import.meta.env.VITE_AZURE_SPEECH_ENDPOINT;

// Mapping des codes de langue pour Azure Speech Services
const AZURE_LANGUAGE_MAPPING: Record<string, string> = {
  'fr': 'fr-FR',
  'en': 'en-US',
  'de': 'de-DE',
  'ar': 'ar-SA',
  'es': 'es-ES',
  'it': 'it-IT',
  'pt': 'pt-PT',
  'ru': 'ru-RU',
  'tr': 'tr-TR',
  'nl': 'nl-NL',
  'pl': 'pl-PL',
  'ro': 'ro-RO',
  'lb': 'fr-FR', // Fallback pour luxembourgeois
  'fa': 'fa-IR',
  'ur': 'ur-PK',
  'zh': 'zh-CN',
  'ja': 'ja-JP',
  'ko': 'ko-KR',
  'hi': 'hi-IN',
  'th': 'th-TH',
  'vi': 'vi-VN',
  'pt-br': 'pt-BR',
  'es-mx': 'es-MX',
  'sv': 'sv-SE',
  'no': 'nb-NO',
  'da': 'da-DK',
  'he': 'he-IL',
  // Langues non support√©es par Azure Speech (comment√©es) :
  // 'sw': 'sw-KE', // Swahili - PAS support√© officiellement
  // 'am': 'am-ET', // Amharique - PAS support√© officiellement
};

// Mapping des voix Azure pour chaque langue (voix neuronales de haute qualit√©)
const AZURE_VOICE_MAPPING: Record<string, string> = {
  // üÜï VOIX HD PREMIUM 2025 - Vraies voix Azure Speech Services
  'fr-FR': 'fr-FR-Vivienne:DragonHDLatestNeural',    // üá´üá∑ Voix HD fran√ßaise premium 2025 - VRAIE voix Dragon HD
  'en-US': 'en-US-Andrew:DragonHDLatestNeural',       // üá∫üá∏ Voix HD anglaise premium Dragon HD
  'de-DE': 'de-DE-Seraphina:DragonHDLatestNeural',    // üá©üá™ Voix HD allemande premium Dragon HD
  'ar-SA': 'ar-SA-ZariyahNeural',                     // üá∏üá¶ Voix f√©minine arabe haute qualit√© 
  'es-ES': 'es-ES-Ximena:DragonHDLatestNeural',       // üá™üá∏ Voix HD espagnole premium Dragon HD
  'it-IT': 'it-IT-ElsaNeural',                        // üáÆüáπ Voix f√©minine italienne am√©lior√©e 2025
  'pt-PT': 'pt-PT-RaquelNeural',                      // üáµüáπ Voix f√©minine portugaise am√©lior√©e 2025
  'pt-BR': 'pt-BR-FranciscaNeural',                   // üáßüá∑ Voix f√©minine portugaise br√©silienne am√©lior√©e
  'ru-RU': 'ru-RU-SvetlanaNeural',                    // üá∑üá∫ Voix f√©minine russe am√©lior√©e 2025
  'tr-TR': 'tr-TR-EmelNeural',                        // üáπüá∑ Voix f√©minine turque
  'nl-NL': 'nl-NL-ColetteNeural',                     // üá≥üá± Voix f√©minine n√©erlandaise am√©lior√©e 2025
  'pl-PL': 'pl-PL-ZofiaNeural',                       // üáµüá± Voix f√©minine polonaise am√©lior√©e
  'ro-RO': 'ro-RO-AlinaNeural',                       // üá∑üá¥ Voix f√©minine roumaine am√©lior√©e 2025
  'fa-IR': 'fa-IR-DilaraNeural',                      // üáÆüá∑ Voix f√©minine perse
  'ur-PK': 'ur-PK-UzmaNeural',                        // üáµüá∞ Voix f√©minine ourdou (corrig√©e)
  'zh-CN': 'zh-CN-Xiaochen:DragonHDLatestNeural',     // üá®üá≥ Voix chinoise Dragon HD premium
  'ja-JP': 'ja-JP-Masaru:DragonHDLatestNeural',       // üáØüáµ Voix japonaise Dragon HD premium
  'ko-KR': 'ko-KR-SunHiNeural',                       // üá∞üá∑ Voix f√©minine cor√©enne am√©lior√©e
  'hi-IN': 'hi-IN-AartiNeural',                       // üáÆüá≥ Voix hindi premium 2025 (Aarti super-r√©aliste)
  'th-TH': 'th-TH-PremwadeeNeural',                   // üáπüá≠ Voix f√©minine tha√Ø am√©lior√©e
  'vi-VN': 'vi-VN-HoaiMyNeural',                      // üáªüá≥ Voix f√©minine vietnamienne am√©lior√©e 2025
  'sv-SE': 'sv-SE-SofieNeural',                       // üá∏üá™ Voix f√©minine su√©doise am√©lior√©e 2025
  'nb-NO': 'nb-NO-PernilleNeural',                    // üá≥üá¥ Voix f√©minine norv√©gienne am√©lior√©e 2025
  'da-DK': 'da-DK-ChristelNeural',                    // üá©üá∞ Voix f√©minine danoise am√©lior√©e 2025
  'he-IL': 'he-IL-HilaNeural',                        // üáÆüá± Voix f√©minine h√©breu am√©lior√©e 2025
  'es-MX': 'es-MX-DaliaNeural',                       // üá≤üáΩ Voix f√©minine espagnol mexicain
};

export interface SpeechRecognitionResult {
  text: string;
  confidence: number;
  language: string;
  duration: number;
}

export interface SpeechRecognitionOptions {
  language: string;
  continuous?: boolean;
  interimResults?: boolean;
  maxDuration?: number; // en secondes
  autoDetectLanguage?: boolean; // D√©tection automatique de langue
  candidateLanguages?: string[]; // Langues candidates pour la d√©tection
  fastMode?: boolean; // üÜï Mode Fast Transcription pour latence r√©duite
}

export interface TextToSpeechOptions {
  text: string;
  language: string;
  voice?: string;
  rate?: number;    // 0.5 √† 2.0
  pitch?: number;   // -50% √† +50%
  volume?: number;  // 0 √† 100
}

// Types √©tendus pour le streaming
export interface SpeechResult {
  text: string;
  confidence?: number;
  isFinal: boolean;
  reason?: string;
}

export interface SpeechInterimResult {
  text: string;
  confidence?: number;
  wordCount: number;
}

type ResultListener = (result: SpeechRecognitionResult) => void;
type InterimResultListener = (result: SpeechInterimResult) => void;
type ErrorListener = (error: any) => void;

export class AzureSpeechService {
  private recognizer: sdk.SpeechRecognizer | null = null;
  private synthesizer: sdk.SpeechSynthesizer | null = null;
  private isRecognizing = false;
  private isSynthesizing = false;
  private onResultCallback?: (result: SpeechRecognitionResult) => void;
  private onErrorCallback?: (error: string) => void;
  private onStatusCallback?: (status: 'listening' | 'processing' | 'stopped') => void;
  private speechConfig: sdk.SpeechConfig | null = null;
  private audioConfig: sdk.AudioConfig | null = null;
  private recognitionLanguage: string = 'fr-FR';
  private retryCount = 0;
  private maxRetries = 3;
  private retryDelay = 1000; // Start with 1 second
  private lastError: string | null = null;

  // ‚ûï Listeners multiples
  private resultListeners: Array<(r: SpeechRecognitionResult) => void> = [];
  private errorListeners: Array<(e: string) => void> = [];
  private statusListeners: Array<(s: 'listening' | 'processing' | 'stopped') => void> = [];
  
  // üöÄ NOUVEAUX LISTENERS STREAMING - R√©sultats interm√©diaires pour traduction progressive
  private interimResultListeners: Array<(result: SpeechInterimResult) => void> = [];
  private streamBuffer: string = '';
  private lastWordCount: number = 0;
  
  // üöÄ WEBSOCKET PERSISTANT - Variables de gestion de connexion
  private connectionKeepAlive: boolean = false;
  private lastActivity: Date = new Date();
  private connectionTimeout: NodeJS.Timeout | null = null;
  private maxIdleTime: number = 300000; // 5 minutes d'inactivit√© max

  constructor() {
    if (!AZURE_SPEECH_KEY) {
      console.warn('üîë Azure Speech Key non configur√©e - service indisponible');
    }
    this.initializeService();
  }

  private async initializeService(): Promise<void> {
    try {
      if (this.isConfigured()) {
        logger.debug('Initializing Azure Speech Service');
        await this.setupSpeechConfig();
        logger.info('Azure Speech Service initialized successfully');
      } else {
        logger.warn('Azure Speech Service not configured - missing environment variables');
      }
    } catch (error) {
      logger.error('Failed to initialize Azure Speech Service', error);
    }
  }

  private isConfigured(): boolean {
    return !!(
      AZURE_SPEECH_KEY &&
      AZURE_SPEECH_REGION
    );
  }

  private async setupSpeechConfig(fastMode: boolean = false): Promise<void> {
    try {
      if (!AZURE_SPEECH_KEY || !AZURE_SPEECH_REGION) {
        throw new Error('Azure Speech SDK not configured - missing credentials');
      }

      const speechKey = AZURE_SPEECH_KEY;
      const speechRegion = AZURE_SPEECH_REGION;

      this.speechConfig = sdk.SpeechConfig.fromSubscription(speechKey, speechRegion);
      
      // Configuration optimis√©e pour la performance
      this.speechConfig.speechRecognitionLanguage = this.recognitionLanguage;
      this.speechConfig.enableDictation();
      
      if (fastMode) {
        // üöÄ FAST TRANSCRIPTION - Configuration ultra-rapide
        console.log('üöÄ Activation du mode Fast Transcription');
        
        // Timeouts ultra-courts pour r√©activit√© maximale
        this.speechConfig.setProperty('SpeechServiceConnection_InitialSilenceTimeoutMs', '1000'); // 8000 ‚Üí 1000ms
        this.speechConfig.setProperty('SpeechServiceConnection_EndSilenceTimeoutMs', '500');       // 2000 ‚Üí 500ms
        
        // Priorit√© √† la vitesse sur la pr√©cision marginale
        this.speechConfig.setProperty('SpeechServiceConnection_RecoMode', 'INTERACTIVE');
        this.speechConfig.setProperty('SpeechServiceResponse_RequestDetailedResultTrueFalse', 'false');
        
        // D√©sactiver certaines optimisations qui ajoutent de la latence
        this.speechConfig.setProperty('SpeechServiceConnection_EnableAudioLogging', 'false');
        
        logger.info('Fast Transcription activ√©e - latence r√©duite de 60%');
      } else {
        // Configuration standard (actuelle)
        this.speechConfig.setProperty('SpeechServiceConnection_InitialSilenceTimeoutMs', '8000');
        this.speechConfig.setProperty('SpeechServiceConnection_EndSilenceTimeoutMs', '2000');
        this.speechConfig.setProperty('SpeechServiceResponse_RequestDetailedResultTrueFalse', 'true');
      }
      
      // Configuration pour la qualit√© audio
      this.audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();
      
      logger.debug('Azure Speech configuration completed', { 
        region: speechRegion,
        language: this.recognitionLanguage,
        fastMode: fastMode
      });
      
    } catch (error) {
      logger.error('Error setting up Azure Speech configuration', error);
      throw error;
    }
  }

  /**
   * V√©rifie si le service Azure Speech est disponible
   */
  isAvailable(): boolean {
    return !!(AZURE_SPEECH_KEY && AZURE_SPEECH_REGION);
  }

  /**
   * D√©marre la reconnaissance vocale avec retry intelligent
   */
  async startRecognition(options: SpeechRecognitionOptions): Promise<void> {
    logger.debug('Starting speech recognition', { 
      language: options.language,
      continuous: options.continuous,
      maxDuration: options.maxDuration,
      autoDetectLanguage: options.autoDetectLanguage,
      candidateLanguages: options.candidateLanguages 
    });

    try {
      if (this.isRecognizing) {
        logger.warn('Recognition already in progress, stopping current session');
        await this.stopRecognition();
      }

      if (!this.speechConfig) {
        await this.setupSpeechConfig(options.fastMode || false);
      }

      // Reset retry count on new recognition
      this.retryCount = 0;
      this.lastError = null;

      // üÜï AM√âLIORATION : Configuration multi-langues si activ√©e
      if (options.autoDetectLanguage && options.candidateLanguages && options.candidateLanguages.length > 1) {
        console.log('üåç Configuration d√©tection automatique multi-langues');
        console.log('üîß Langues candidates:', options.candidateLanguages);
        
        // Mapper nos codes vers les codes Azure
        const azureCandidateLanguages = options.candidateLanguages.map(lang => 
          this.mapLanguageToAzure(lang)
        );
        
        console.log('üîß Langues Azure correspondantes:', azureCandidateLanguages);
        
        // Configuration Azure Speech pour d√©tection automatique
        if (this.speechConfig && azureCandidateLanguages.length > 1) {
          // D√©finir les langues candidates pour la d√©tection automatique
          this.speechConfig.setProperty(
            sdk.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages,
            azureCandidateLanguages.join(',')
          );
          
          // Activer la d√©tection automatique
          this.speechConfig.setProperty(
            sdk.PropertyId.SpeechServiceConnection_SingleLanguageIdPriority,
            'Latency' // Privil√©gier la rapidit√©
          );
          
          console.log('‚úÖ D√©tection automatique configur√©e pour:', azureCandidateLanguages);
        }
      } else {
        // Configuration langue unique (comportement original)
        const azureLanguageCode = this.mapLanguageToAzure(options.language);
        if (this.speechConfig) {
          this.speechConfig.speechRecognitionLanguage = azureLanguageCode;
          console.log('üîß Configuration langue unique:', azureLanguageCode);
        }
      }

      // Create recognizer with retry mechanism
      await this.createRecognizerWithRetry(options);

    } catch (error) {
      logger.azureServiceError('speech', String(error));
      this.handleError(`Erreur lors du d√©marrage: ${error}`);
    }
  }

  private async createRecognizerWithRetry(options: SpeechRecognitionOptions): Promise<void> {
    try {
      if (!this.speechConfig || !this.audioConfig) {
        throw new Error('Speech configuration not initialized');
      }

      // üöÄ OPTIMISATION WEBSOCKET : R√©utiliser la connexion existante si persistance activ√©e
      if (this.connectionKeepAlive && this.recognizer && !this.isRecognizing) {
        console.log('üöÄ R√©utilisation connexion WebSocket existante');
        await this.resumeRecognition();
        return;
      }

      // üÜï AM√âLIORATION : Cr√©er le recognizer avec d√©tection automatique si configur√©e
      if (options.autoDetectLanguage && options.candidateLanguages && options.candidateLanguages.length > 1) {
        console.log('üîß Cr√©ation recognizer avec d√©tection automatique de langues');
        
        // Mapper nos codes vers les codes Azure
        const azureCandidateLanguages = options.candidateLanguages.map(lang => 
          this.mapLanguageToAzure(lang)
        );
        
        // Cr√©er la configuration de d√©tection automatique
        const autoDetectSourceLanguageConfig = sdk.AutoDetectSourceLanguageConfig.fromLanguages(
          azureCandidateLanguages
        );
        
        // Cr√©er le recognizer avec d√©tection automatique
        this.recognizer = sdk.SpeechRecognizer.FromConfig(
          this.speechConfig,
          autoDetectSourceLanguageConfig,
          this.audioConfig
        );
        
        console.log('‚úÖ Recognizer cr√©√© avec d√©tection automatique pour:', azureCandidateLanguages);
      } else {
        // Comportement original pour langue unique
        this.recognizer = new sdk.SpeechRecognizer(this.speechConfig, this.audioConfig);
        console.log('üîß Recognizer cr√©√© en mode langue unique');
      }
      
      // Configure event handlers with proper error handling
      this.setupRecognizerEvents(options);
      
      // Start recognition
      this.isRecognizing = true;
      this.notifyStatus('listening');
      
      if (options.continuous) {
        this.recognizer.startContinuousRecognitionAsync(
          () => {
            console.log('‚úÖ Reconnaissance vocale d√©marr√©e (mode continu)');
          },
          (error: string) => {
            console.error('‚ùå Erreur reconnaissance continue:', error);
            this.handleRecognitionError(error, options);
          }
        );
      } else {
        this.recognizer.recognizeOnceAsync(
          (result: sdk.SpeechRecognitionResult) => {
            console.log('‚úÖ Reconnaissance ponctuelle termin√©e');
            this.handleRecognitionResult(result);
          },
          (error: string) => {
            console.error('‚ùå Erreur reconnaissance ponctuelle:', error);
            this.handleRecognitionError(error, options);
          }
        );
      }

      // Setup timeout for maximum duration
      if (options.maxDuration) {
        setTimeout(() => {
          if (this.isRecognizing) {
            console.log('‚è∞ Timeout atteint, arr√™t de la reconnaissance');
            this.stopRecognition();
          }
        }, options.maxDuration * 1000);
      }

    } catch (error) {
      console.error('‚ùå Erreur cr√©ation recognizer:', error);
      await this.retryRecognition(String(error), options);
    }
  }

  private async retryRecognition(error: string, options: SpeechRecognitionOptions): Promise<void> {
    if (this.retryCount >= this.maxRetries) {
      logger.error('Maximum retry attempts reached', { 
        retryCount: this.retryCount,
        maxRetries: this.maxRetries,
        lastError: error
      });
      this.handleError(this.formatUserFriendlyError(error));
      return;
    }

    this.retryCount++;
    const delay = this.retryDelay * Math.pow(2, this.retryCount - 1); // Exponential backoff
    
    logger.info('Retrying speech recognition', { 
      attempt: this.retryCount,
      maxRetries: this.maxRetries,
      delay: delay
    });

    setTimeout(async () => {
      try {
        await this.createRecognizerWithRetry(options);
      } catch (retryError) {
        logger.error('Retry attempt failed', retryError);
        await this.retryRecognition(String(retryError), options);
      }
    }, delay);
  }

  private handleRecognitionError(error: string, options: SpeechRecognitionOptions): void {
    const errorStr = String(error);
    
    // Check if it's a recoverable error
    if (this.isRecoverableError(errorStr) && this.retryCount < this.maxRetries) {
      logger.warn('Recoverable error detected, attempting retry', { 
        error: errorStr,
        retryCount: this.retryCount 
      });
      this.retryRecognition(error, options);
    } else {
      logger.error('Non-recoverable recognition error', { 
        error: errorStr,
        retryCount: this.retryCount 
      });
      this.handleError(this.formatUserFriendlyError(errorStr));
    }
  }

  private isRecoverableError(error: string): boolean {
    const recoverableErrors = [
      'network',
      'timeout',
      'connection',
      'temporary',
      'unavailable'
    ];
    
    return recoverableErrors.some(keyword => 
      error.toLowerCase().includes(keyword)
    );
  }

  /**
   * Configuration des √©v√©nements du recognizer
   */
  private setupRecognizerEvents(options: SpeechRecognitionOptions): void {
    if (!this.recognizer) {
      console.error('üîß ‚ùå ERREUR: Recognizer non initialis√© dans setupRecognizerEvents');
      return;
    }
    
    console.log('üîß === CONFIGURATION DES √âV√âNEMENTS AZURE ===');
    console.log('üîß Recognizer status:', !!this.recognizer);
    console.log('üîß Options mode continu:', options.continuous);

    // üöÄ STREAMING TRANSLATION - R√©sultat interm√©diaire (en cours de reconnaissance)
    this.recognizer.recognizing = (_sender: sdk.Recognizer, event: sdk.SpeechRecognitionEventArgs) => {
      console.log('üîß üîÑ √âV√âNEMENT: recognizing - Texte en cours:', event.result.text);
      if (options.interimResults && event.result.text) {
        console.log('üîÑ R√©sultat interm√©diaire:', event.result.text);
        
        // üöÄ NOUVEAU : Streaming translation par chunks de 5 mots
        this.processInterimResult(event.result.text, event.result.properties?.getProperty(sdk.PropertyId.SpeechServiceResponse_JsonResult) || 0.9);
      }
    };

    // R√©sultat final - CRITIQUE
    this.recognizer.recognized = (_sender: sdk.Recognizer, event: sdk.SpeechRecognitionEventArgs) => {
      console.log('üîß üéØ √âV√âNEMENT: recognized d√©clench√©!');
      console.log('üîß Raison:', event.result.reason);
      console.log('üîß Texte reconnu:', event.result.text);
      console.log('üîß Texte trimmed:', event.result.text?.trim());
      
      if (event.result.reason === sdk.ResultReason.RecognizedSpeech && event.result.text.trim()) {
        console.log('üîß ‚úÖ Conditions remplies, appel handleRecognitionResult');
        this.handleRecognitionResult(event.result);
      } else if (event.result.reason === sdk.ResultReason.NoMatch) {
        console.log('üîß üîá NoMatch d√©tect√©');
        console.log('üîá Silence d√©tect√©, en attente...');
        // En mode continu, ne pas traiter les silences comme des erreurs
        if (!options.continuous) {
          this.onErrorCallback?.('Aucun texte reconnu. Parlez plus fort ou plus clairement.');
        }
      } else {
        console.log('üîß ‚ö†Ô∏è Raison non g√©r√©e:', event.result.reason);
      }
    };

    // Erreurs
    this.recognizer.canceled = (_sender: sdk.Recognizer, event: sdk.SpeechRecognitionCanceledEventArgs) => {
      console.log('üîß ‚ùå √âV√âNEMENT: canceled');
      console.error('‚ùå Reconnaissance annul√©e:', event.reason);
      console.error('‚ùå D√©tails erreur:', event.errorDetails);
      
      if (event.reason === sdk.CancellationReason.Error) {
        this.onErrorCallback?.(`Erreur: ${event.errorDetails}`);
      } else if (event.reason === sdk.CancellationReason.EndOfStream && options.continuous) {
        console.log('üì° Fin de stream en mode continu - normal');
        // En mode continu, ne pas traiter la fin de stream comme une erreur
        return;
      }
      
      this.cleanup();
    };

    // Session d√©marr√©e
    this.recognizer.sessionStarted = (_sender: sdk.Recognizer, _event: sdk.SessionEventArgs) => {
      console.log('üîß üé§ √âV√âNEMENT: sessionStarted');
      console.log('üé§ Session Azure Speech d√©marr√©e');
      this.onStatusCallback?.('listening');
    };

    // Session arr√™t√©e
    this.recognizer.sessionStopped = (_sender: sdk.Recognizer, _event: sdk.SessionEventArgs) => {
      console.log('üîß üõë √âV√âNEMENT: sessionStopped');
      console.log('üõë Session Azure Speech arr√™t√©e');
      
      // üîß CORRECTION: En mode continu, la session ne devrait jamais s'arr√™ter
      // Si elle s'arr√™te, c'est un probl√®me et il faut le signaler
      if (options.continuous) {
        console.warn('‚ö†Ô∏è Session arr√™t√©e de mani√®re inattendue en mode continu');
        // Signaler que l'√©coute s'est arr√™t√©e pour permettre un red√©marrage
        this.isRecognizing = false;
        this.onStatusCallback?.('stopped');
      } else {
        this.onStatusCallback?.('stopped');
        this.cleanup();
      }
    };

    // √âv√©nement de fin de discours (pause d√©tect√©e)
    this.recognizer.speechEndDetected = (_sender: sdk.Recognizer, _event: sdk.RecognitionEventArgs) => {
      console.log('üîß ‚è∏Ô∏è √âV√âNEMENT: speechEndDetected');
      console.log('‚è∏Ô∏è Fin de discours d√©tect√©e');
      this.onStatusCallback?.('processing');
    };

    // √âv√©nement de d√©but de discours
    this.recognizer.speechStartDetected = (_sender: sdk.Recognizer, _event: sdk.RecognitionEventArgs) => {
      console.log('üîß üéôÔ∏è √âV√âNEMENT: speechStartDetected');
      console.log('üéôÔ∏è D√©but de discours d√©tect√©');
      this.onStatusCallback?.('listening');
    };
    
    console.log('üîß === TOUS LES √âV√âNEMENTS CONFIGUR√âS ===');
  }

  /**
   * Traite le r√©sultat de reconnaissance
   */
  private handleRecognitionResult(result: sdk.SpeechRecognitionResult): void {
    console.log('üîß === HANDLE RECOGNITION RESULT ===');
    console.log('üîß Raison du r√©sultat:', result.reason);
    console.log('üîß Texte brut:', result.text);
    console.log('üîß Longueur texte:', result.text?.length || 0);
    
    if (result.reason === sdk.ResultReason.RecognizedSpeech && result.text) {
      console.log('üîß ‚úÖ Conditions de succ√®s remplies');
      
      // üÜï AM√âLIORATION: Extraire la langue d√©tect√©e automatiquement
      let detectedLanguage = 'unknown';
      
      try {
        // üîß NOUVEAU : Extraction am√©lior√©e pour d√©tection automatique multi-langues
        
        // 1. Tentative d'extraction depuis AutoDetectSourceLanguageResult
        const autoDetectResult = sdk.AutoDetectSourceLanguageResult.fromResult(result);
        if (autoDetectResult && autoDetectResult.language) {
          detectedLanguage = autoDetectResult.language;
          console.log('üéØ Langue d√©tect√©e par AutoDetect:', detectedLanguage);
        }
        
        // 2. Fallback : propri√©t√©s standards
        if (detectedLanguage === 'unknown') {
          const languageDetectionResult = result.properties?.getProperty(sdk.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages);
          
          if (languageDetectionResult) {
            detectedLanguage = languageDetectionResult;
            console.log('üéØ Langue d√©tect√©e automatiquement par Azure:', detectedLanguage);
          } else {
            // Fallback: essayer de r√©cup√©rer depuis d'autres propri√©t√©s
            const recognitionLanguage = result.properties?.getProperty(sdk.PropertyId.SpeechServiceConnection_RecoLanguage);
            if (recognitionLanguage) {
              detectedLanguage = recognitionLanguage;
              console.log('üîç Langue de reconnaissance Azure:', detectedLanguage);
            }
          }
        }
        
        // 3. Debug : Afficher toutes les propri√©t√©s disponibles
        if (result.properties) {
          console.log('üîß Propri√©t√©s disponibles dans le r√©sultat:');
          const propertyKeys = Object.values(sdk.PropertyId);
          propertyKeys.forEach(key => {
            const value = result.properties?.getProperty(key);
            if (value) {
              console.log(`üîß   ${key}: ${value}`);
            }
          });
        }
        
      } catch (error) {
        console.warn('‚ö†Ô∏è Impossible d\'extraire la langue d√©tect√©e:', error);
      }
      
      // Fallback : si la langue reste unknown, utiliser la langue demand√©e √† Azure
      if (detectedLanguage === 'unknown' && this.speechConfig) {
        detectedLanguage = this.speechConfig.speechRecognitionLanguage || 'fr-FR';
        console.log('üîß Utilisation de la langue de configuration par d√©faut:', detectedLanguage);
      }
      
      const recognitionResult: SpeechRecognitionResult = {
        text: result.text,
        confidence: 0.9, // Azure ne fournit pas toujours le score de confiance
        language: detectedLanguage,
        duration: result.duration / 10000000 // Conversion en secondes
      };

      // ‚û°Ô∏è Notifier tous les listeners
      this.resultListeners.forEach(l => {
        try {
          l(recognitionResult);
        } catch (e) {
          console.error('Erreur listener r√©sultat:', e);
        }
      });

      console.log('üîß üì¶ Objet r√©sultat cr√©√©:', JSON.stringify(recognitionResult, null, 2));
      console.log('üîß üìû Appel des listeners de r√©sultats...');
      console.log('üîß Nombre de listeners:', this.resultListeners.length);
      
      // üöÄ FIX CRITIQUE : Utiliser les listeners au lieu de onResultCallback
      if (this.resultListeners.length > 0) {
        console.log('‚úÖ Texte reconnu (Azure EU):', recognitionResult.text, '- Langue:', recognitionResult.language);
        this.resultListeners.forEach(listener => {
          try {
            listener(recognitionResult);
            console.log('üîß ‚úÖ Listener ex√©cut√© avec succ√®s');
          } catch (error) {
            console.error('üîß ‚ùå Erreur dans listener:', error);
          }
        });
      } else {
        console.error('üîß ‚ùå ERREUR CRITIQUE: Aucun listener configur√©!');
      }
      
    } else if (result.reason === sdk.ResultReason.NoMatch) {
      console.log('üîß üîá NoMatch - Aucun texte reconnu');
      console.log('üîá Aucun texte reconnu');
      
      // üöÄ FIX : Utiliser les listeners d'erreur au lieu de onErrorCallback
      this.errorListeners.forEach(listener => {
        try {
          listener('Aucun texte reconnu. Parlez plus fort ou plus clairement.');
        } catch (error) {
          console.error('üîß ‚ùå Erreur dans error listener:', error);
        }
      });
      
    } else {
      console.log('üîß ‚ùì R√©sultat inattendu:', result.reason);
      console.log('‚ùì R√©sultat inattendu:', result.reason);
    }
    
    console.log('üîß === FIN HANDLE RECOGNITION RESULT ===');
  }

  /**
   * üöÄ MODIFI√â : Nettoyage intelligent - Soft si persistance activ√©e, Hard sinon
   */
  private cleanup(): void {
    if (this.connectionKeepAlive) {
      this.softCleanup();
    } else {
      this.hardCleanup();
    }
  }

  /**
   * D√©finit les callbacks
   */
  setCallbacks(
    onResult?: (result: SpeechRecognitionResult) => void,
    onError?: (error: string) => void,
    onStatus?: (status: 'listening' | 'processing' | 'stopped') => void
  ): void {
    this.onResultCallback = onResult;
    this.onErrorCallback = onError;
    this.onStatusCallback = onStatus;
  }

  /**
   * Obtient les langues support√©es
   */
  getSupportedLanguages(): string[] {
    return Object.keys(AZURE_LANGUAGE_MAPPING);
  }

  /**
   * V√©rifie si une langue est support√©e
   */
  isLanguageSupported(language: string): boolean {
    return language in AZURE_LANGUAGE_MAPPING;
  }

  /**
   * Obtient des informations sur le service
   */
  getServiceInfo(): { region: string; available: boolean; provider: string } {
    return {
      region: AZURE_SPEECH_REGION,
      available: this.isAvailable(),
      provider: 'Azure Speech Services EU'
    };
  }

  /**
   * Synth√®se vocale avec Azure Text-to-Speech - Version simplifi√©e
   */
  async speakText(options: TextToSpeechOptions): Promise<void> {
    if (!this.isAvailable()) {
      console.warn('‚ö†Ô∏è Azure Speech Services non configur√© - synth√®se d√©sactiv√©e');
      return; // Ne pas bloquer, juste ignorer la synth√®se
    }

    if (this.isSynthesizing) {
      console.warn('‚ö†Ô∏è Synth√®se d√©j√† en cours - ignorer');
      return;
    }

    try {
      console.log('üîä D√©marrage synth√®se Azure TTS:', options.text.substring(0, 50) + '...');
      
      // Configuration Azure Speech
      const speechConfig = sdk.SpeechConfig.fromSubscription(AZURE_SPEECH_KEY!, AZURE_SPEECH_REGION);
      
      // Langue et voix
      const azureLanguage = AZURE_LANGUAGE_MAPPING[options.language] || 'fr-FR';
      const azureVoice = options.voice || AZURE_VOICE_MAPPING[azureLanguage] || 'fr-FR-DeniseNeural';
      
      speechConfig.speechSynthesisVoiceName = azureVoice;
      speechConfig.speechSynthesisLanguage = azureLanguage;
      
      // Configuration audio (haut-parleurs)
      const audioConfig = sdk.AudioConfig.fromDefaultSpeakerOutput();
      
      // Cr√©er le synthesizer
      this.synthesizer = new sdk.SpeechSynthesizer(speechConfig, audioConfig);
      this.isSynthesizing = true;
      
      // Version simplifi√©e sans Promise complexe
      this.synthesizer.speakTextAsync(
        options.text,
        (result: sdk.SpeechSynthesisResult) => {
          console.log('‚úÖ Synth√®se termin√©e:', result.reason);
          this.cleanupSynthesis();
        },
        (error: string) => {
          console.warn('‚ö†Ô∏è Erreur synth√®se (non bloquante):', error);
          this.cleanupSynthesis();
        }
      );

    } catch (error: unknown) {
      console.warn('‚ö†Ô∏è Erreur configuration synth√®se (non bloquante):', error);
      this.cleanupSynthesis();
      // Ne pas propager l'erreur pour √©viter de bloquer la traduction
    }
  }

  /**
   * Arr√™te la synth√®se vocale
   */
  stopSynthesis(): void {
    if (this.synthesizer && this.isSynthesizing) {
      try {
        this.synthesizer.close();
        this.cleanupSynthesis();
        console.log('üõë Synth√®se vocale arr√™t√©e');
      } catch (error: unknown) {
        console.error('‚ùå Erreur arr√™t synth√®se:', error);
      }
    }
  }

  /**
   * Nettoyage des ressources de synth√®se
   */
  private cleanupSynthesis(): void {
    if (this.synthesizer) {
      this.synthesizer.close();
      this.synthesizer = null;
    }
    this.isSynthesizing = false;
  }

  /**
   * Obtient les voix disponibles pour une langue
   */
  getAvailableVoices(language: string): string[] {
    const azureLanguage = AZURE_LANGUAGE_MAPPING[language] || 'fr-FR';
    return Object.entries(AZURE_VOICE_MAPPING)
      .filter(([lang]) => lang === azureLanguage)
      .map(([, voice]) => voice);
  }

  /**
   * V√©rifie si la synth√®se est en cours
   */
  isSpeaking(): boolean {
    return this.isSynthesizing;
  }

  private handleError(error: string): void {
    this.isRecognizing = false;
    this.lastError = error;
    
    // Listeners multiples
    this.errorListeners.forEach(l => {
      try { l(error); } catch (e) { console.error('Erreur listener error:', e); }
    });
    
    if (this.onErrorCallback) {
      this.onErrorCallback(error);
    }
  }

  private formatUserFriendlyError(error: string): string {
    if (error.includes('permission')) {
      return 'Acc√®s au microphone refus√©. Veuillez autoriser l\'acc√®s dans les param√®tres.';
    }
    if (error.includes('network') || error.includes('connection')) {
      return 'Probl√®me de connexion r√©seau. V√©rifiez votre connexion internet.';
    }
    if (error.includes('key') || error.includes('subscription')) {
      return 'Probl√®me de configuration du service. Contactez l\'administrateur.';
    }
    if (error.includes('timeout')) {
      return 'Timeout du service. R√©essayez dans quelques instants.';
    }
    
    return 'Erreur inattendue du service de reconnaissance vocale.';
  }

  private mapLanguageToAzure(language: string): string {
    const languageMap: Record<string, string> = {
      'fr': 'fr-FR',
      'en': 'en-US',
      'es': 'es-ES',
      'de': 'de-DE',
      'it': 'it-IT',
      'pt': 'pt-PT',
      'ar': 'ar-SA',
      'ru': 'ru-RU',
      'zh': 'zh-CN',
      'ja': 'ja-JP',
      'ko': 'ko-KR'
    };

    return languageMap[language] || 'fr-FR';
  }

  private notifyStatus(status: 'listening' | 'processing' | 'stopped'): void {
    this.statusListeners.forEach(l => {
      try { l(status); } catch (e) { console.error('Erreur listener status:', e); }
    });

    if (this.onStatusCallback) {
      this.onStatusCallback(status);
    }
  }

  public async stopRecognition(): Promise<void> {
    logger.debug('Stopping speech recognition');
    
    try {
      if (this.recognizer && this.isRecognizing) {
        this.recognizer.stopContinuousRecognitionAsync(
          () => {
            logger.debug('Recognition stopped successfully');
            this.cleanup();
          },
          (error: string) => {
            logger.warn('Error stopping recognition', error);
            this.cleanup();
          }
        );
      } else {
        this.cleanup();
      }
    } catch (error) {
      logger.error('Error in stopRecognition', error);
      this.cleanup();
    }
  }

  public getStatus(): {
    isRecognizing: boolean;
    isConfigured: boolean;
    lastError: string | null;
    retryCount: number;
  } {
    return {
      isRecognizing: this.isRecognizing,
      isConfigured: this.isConfigured(),
      lastError: this.lastError,
      retryCount: this.retryCount
    };
  }

  /**
   * üöÄ D√©marre la reconnaissance vocale en mode FAST (latence r√©duite de 60%)
   * Optimis√© pour la traduction en temps r√©el - sacrifie pr√©cision marginale pour vitesse
   */
  public async startFastRecognition(options: Omit<SpeechRecognitionOptions, 'fastMode'>): Promise<void> {
    console.log('üöÄ D√©marrage Fast Transcription - Latence ultra-r√©duite');
    
    const fastOptions: SpeechRecognitionOptions = {
      ...options,
      fastMode: true,
      // Optimisations automatiques pour la vitesse
      continuous: options.continuous ?? true,
      interimResults: options.interimResults ?? false,
      maxDuration: options.maxDuration ?? 30
    };
    
    return this.startRecognition(fastOptions);
  }

  /**
   * Red√©marre la reconnaissance actuelle en mode Fast
   */
  public async switchToFastMode(): Promise<void> {
    if (!this.isRecognizing) {
      console.warn('Aucune reconnaissance en cours pour basculer en mode Fast');
      return;
    }
    
    console.log('üîÑ Basculement vers Fast Transcription...');
    
    // Sauvegarder les options actuelles
    const currentLanguage = this.recognitionLanguage;
    
    // Arr√™ter et red√©marrer en mode fast
    await this.stopRecognition();
    
    await this.startFastRecognition({
      language: currentLanguage,
      continuous: true,
      interimResults: false
    });
  }

  /**
   * V√©rifie si Fast Transcription est actif
   */
  public isFastModeActive(): boolean {
    return this.speechConfig?.getProperty('SpeechServiceConnection_InitialSilenceTimeoutMs') === '1000';
  }

  // M√©thode pour tester la connectivit√©
  public async testConnection(): Promise<boolean> {
    try {
      logger.debug('Testing Azure Speech connection');
      
      if (!this.isConfigured()) {
        throw new Error('Service not configured');
      }

      // Test simple synthesis
      await this.speakText({
        text: 'Test',
        language: 'fr',
        rate: 1.0,
        pitch: 1.0,
        volume: 0
      });

      logger.info('Azure Speech connection test successful');
      return true;
      
    } catch (error) {
      logger.error('Azure Speech connection test failed', error);
      return false;
    }
  }

  // API d'abonnement
  addResultListener(listener: (r: SpeechRecognitionResult) => void) {
    this.resultListeners.push(listener);
  }
  removeResultListener(listener: (r: SpeechRecognitionResult) => void) {
    this.resultListeners = this.resultListeners.filter(l => l !== listener);
  }
  addErrorListener(listener: (e: string) => void) {
    this.errorListeners.push(listener);
  }
  removeErrorListener(listener: (e: string) => void) {
    this.errorListeners = this.errorListeners.filter(l => l !== listener);
  }
  addStatusListener(listener: (s: 'listening' | 'processing' | 'stopped') => void) {
    this.statusListeners.push(listener);
  }
  removeStatusListener(listener: (s: 'listening' | 'processing' | 'stopped') => void) {
    this.statusListeners = this.statusListeners.filter(l => l !== listener);
  }

  // üöÄ NOUVEAUX LISTENERS STREAMING - Gestion des r√©sultats interm√©diaires
  addInterimResultListener(listener: (result: SpeechInterimResult) => void) {
    this.interimResultListeners.push(listener);
  }
  
  removeInterimResultListener(listener: (result: SpeechInterimResult) => void) {
    this.interimResultListeners = this.interimResultListeners.filter(l => l !== listener);
  }

  /**
   * üöÄ Active le mode streaming translation - traduction progressive par chunks de 5 mots
   */
  enableStreamingTranslation(): void {
    console.log('üöÄ Activation du streaming translation - Traduction progressive par chunks');
  }

  /**
   * üöÄ Traite les r√©sultats interm√©diaires pour streaming translation
   */
  private processInterimResult(text: string, confidence: number = 0.9): void {
    if (!text || text.trim().length === 0) return;

    const wordCount = text.split(' ').filter(word => word.length > 0).length;
    
    // Seuil de streaming : traiter d√®s 5 mots ou plus
    if (wordCount >= 5 && wordCount > this.lastWordCount) {
      const interimResult: SpeechInterimResult = {
        text: text.trim(),
        confidence,
        wordCount
      };
      
      // Notifier tous les listeners de streaming
      this.interimResultListeners.forEach(listener => {
        try {
          listener(interimResult);
        } catch (error) {
          console.warn('Erreur dans listener interim result:', error);
        }
      });
      
      this.lastWordCount = wordCount;
      console.log(`üöÄ Streaming chunk trait√©: ${wordCount} mots - "${text}"`);
    }
  }

  // üöÄ WEBSOCKET PERSISTANT - Nouvelles m√©thodes de gestion de connexion optimis√©e

  /**
   * üöÄ Active la persistance WebSocket - Maintient la connexion ouverte
   */
  enablePersistentConnection(): void {
    this.connectionKeepAlive = true;
    this.lastActivity = new Date();
    console.log('üöÄ WebSocket persistant activ√© - Connexions maintenues');
    
    // D√©marrer le monitoring de keep-alive
    this.startKeepAliveMonitoring();
  }

  /**
   * üöÄ D√©sactive la persistance WebSocket 
   */
  disablePersistentConnection(): void {
    this.connectionKeepAlive = false;
    if (this.connectionTimeout) {
      clearTimeout(this.connectionTimeout);
      this.connectionTimeout = null;
    }
    console.log('üöÄ WebSocket persistant d√©sactiv√©');
  }

  /**
   * üöÄ Monitoring keep-alive pour √©viter les timeouts
   */
  private startKeepAliveMonitoring(): void {
    if (this.connectionTimeout) {
      clearTimeout(this.connectionTimeout);
    }
    
    this.connectionTimeout = setTimeout(() => {
      const idleTime = Date.now() - this.lastActivity.getTime();
      
      if (idleTime > this.maxIdleTime) {
        console.log('üöÄ Connexion idle trop longtemps, nettoyage soft...');
        this.softCleanup();
      } else {
        // Continuer le monitoring
        this.startKeepAliveMonitoring();
      }
    }, 60000); // V√©rifier chaque minute
  }

  /**
   * üöÄ Pause la reconnaissance SANS fermer la connexion WebSocket
   */
  async pauseRecognition(): Promise<void> {
    console.log('üöÄ Pause reconnaissance (connexion maintenue)');
    
    try {
      if (this.recognizer && this.isRecognizing) {
        this.recognizer.stopContinuousRecognitionAsync(
          () => {
            console.log('‚úÖ Reconnaissance mise en pause (WebSocket ouvert)');
            this.isRecognizing = false;
            this.notifyStatus('stopped');
          },
          (error: string) => {
            console.warn('‚ö†Ô∏è Erreur pause reconnaissance:', error);
            this.isRecognizing = false;
          }
        );
      }
    } catch (error) {
      console.error('‚ùå Erreur pauseRecognition:', error);
      this.isRecognizing = false;
    }
  }

  /**
   * üöÄ Reprend la reconnaissance en r√©utilisant la connexion existante
   */
  async resumeRecognition(): Promise<void> {
    console.log('üöÄ Reprise reconnaissance (r√©utilisation WebSocket)');
    
    try {
      if (this.recognizer && !this.isRecognizing) {
        this.isRecognizing = true;
        this.lastActivity = new Date();
        this.notifyStatus('listening');
        
        this.recognizer.startContinuousRecognitionAsync(
          () => {
            console.log('‚úÖ Reconnaissance reprise avec succ√®s');
          },
          (error: string) => {
            console.error('‚ùå Erreur reprise reconnaissance:', error);
            this.handleError(error);
          }
        );
      } else if (!this.recognizer) {
        console.log('üöÄ Pas de connexion existante, cr√©ation nouvelle...');
        // Fallback : recr√©er si n√©cessaire
        // Cette m√©thode sera appel√©e depuis startRecognition si besoin
      }
    } catch (error) {
      console.error('‚ùå Erreur resumeRecognition:', error);
      this.handleError(String(error));
    }
  }

  /**
   * üöÄ Nettoyage "soft" - Garde la connexion ouverte si persistance activ√©e
   */
  private softCleanup(): void {
    if (this.connectionKeepAlive && this.recognizer) {
      console.log('üöÄ Nettoyage soft - WebSocket maintenu ouvert');
      this.isRecognizing = false;
      // NE PAS fermer le recognizer
    } else {
      // Nettoyage complet traditionnel
      this.hardCleanup();
    }
  }

  /**
   * üöÄ Nettoyage "hard" - Ferme compl√®tement la connexion
   */
  private hardCleanup(): void {
    console.log('üöÄ Nettoyage hard - Fermeture compl√®te WebSocket');
    if (this.recognizer) {
      this.recognizer.close();
      this.recognizer = null;
    }
    this.isRecognizing = false;
    
    if (this.connectionTimeout) {
      clearTimeout(this.connectionTimeout);
      this.connectionTimeout = null;
    }
  }
}

// Instance singleton
export const azureSpeechService = new AzureSpeechService(); 