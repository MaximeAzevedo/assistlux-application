import { useState, useRef, useCallback, useEffect } from 'react';
import { useTranslation } from 'react-i18next';
import { translateText, translateTextForInterview, initializeTranslationCache } from '../lib/translation';
import { detectLanguage } from '../lib/translation';
import { azureSpeechService } from '../services/azureSpeechService';
import { 
  UseInterviewTranslatorProps, 
  UseInterviewTranslatorReturn,
  TranslationMessage,
  SessionStats,
  InterviewSummary,
  SpeakerRole
} from '../types/interviewTranslator';

export const useInterviewTranslator = ({
  userLanguage,
  onSessionUpdate
}: UseInterviewTranslatorProps): UseInterviewTranslatorReturn => {
  
  const { i18n } = useTranslation();
  const assistantLanguage = i18n.language || 'fr';
  
  // Ã‰tats principaux (simplifiÃ©s)
  const [isListening, setIsListening] = useState(false);
  const [isTranslating, setIsTranslating] = useState(false);
  const [translationQuality, setTranslationQuality] = useState(85);
  const [messages, setMessages] = useState<TranslationMessage[]>([]);
  const [sessionStats, setSessionStats] = useState<SessionStats | null>(null);
  const [isStreaming, setIsStreaming] = useState(false); // ğŸš€ NOUVEAU : Ã‰tat streaming translation
  
  // Refs pour Ã©viter les re-renders et gÃ©rer les Ã©tats asynchrones
  const isProcessingRef = useRef(false);
  const lastProcessedText = useRef<string>('');
  const lastProcessedTime = useRef<number>(0);
  const sessionStartTime = useRef<Date | null>(null);
  const streamingBuffer = useRef<string>(''); // ğŸš€ NOUVEAU : Buffer pour streaming

  // Fonction amÃ©liorÃ©e de synthÃ¨se vocale
  const speakTranslation = useCallback(async (text: string, language: string) => {
    try {
      console.log(`ğŸ”Š SynthÃ¨se vocale en ${language}: "${text}"`);
      
      // PrioritÃ© 1: Utiliser Azure TTS si disponible
      if (azureSpeechService.isAvailable()) {
        try {
          await azureSpeechService.speakText({
            text: text,
            language: language,
            rate: 0.9,
            pitch: 1.0
          });
          return;
        } catch (error) {
          console.warn('Erreur Azure TTS, fallback vers Web Speech:', error);
        }
      }

      // PrioritÃ© 2: Fallback vers Web Speech API
      if ('speechSynthesis' in window) {
        // ArrÃªter toute synthÃ¨se en cours
        speechSynthesis.cancel();
        
        const utterance = new SpeechSynthesisUtterance(text);
        
        // Configuration avancÃ©e de la voix
        const voices = speechSynthesis.getVoices();
        let selectedVoice = null;
        
        // SÃ©lection intelligente de la voix selon la langue
        const voiceSelectors = {
          'fr': (v: SpeechSynthesisVoice) => v.lang.startsWith('fr') && (v.name.includes('Thomas') || v.name.includes('Marie')),
          'en': (v: SpeechSynthesisVoice) => v.lang.startsWith('en') && (v.name.includes('Alex') || v.name.includes('Samantha')),
          'ar': (v: SpeechSynthesisVoice) => v.lang.startsWith('ar'),
          'es': (v: SpeechSynthesisVoice) => v.lang.startsWith('es'),
          'de': (v: SpeechSynthesisVoice) => v.lang.startsWith('de')
        };
        
        const selector = voiceSelectors[language as keyof typeof voiceSelectors];
        if (selector) {
          selectedVoice = voices.find(selector) || voices.find(v => v.lang.startsWith(language));
        }
        
        if (selectedVoice) {
          utterance.voice = selectedVoice;
          utterance.lang = selectedVoice.lang;
        } else {
          // Mapping de langues par dÃ©faut
          const langMapping = {
            'fr': 'fr-FR',
            'en': 'en-US', 
            'ar': 'ar-SA',
            'es': 'es-ES',
            'de': 'de-DE'
          };
          utterance.lang = langMapping[language as keyof typeof langMapping] || 'fr-FR';
        }
        
        // Configuration optimisÃ©e
        utterance.rate = 0.9;
        utterance.pitch = 1.0;
        utterance.volume = 0.8;
        
        // Gestion des erreurs de synthÃ¨se
        utterance.onerror = (event) => {
          console.error('Erreur synthÃ¨se vocale:', event.error);
        };
        
        utterance.onend = () => {
          console.log('âœ… SynthÃ¨se vocale terminÃ©e');
        };
        
        speechSynthesis.speak(utterance);
      } else {
        console.warn('SynthÃ¨se vocale non supportÃ©e sur ce navigateur');
      }
    } catch (error) {
      console.error('Erreur gÃ©nÃ©rale synthÃ¨se vocale:', error);
    }
  }, []);

  // Initialisation simple
  useEffect(() => {
    if (!sessionStartTime.current) {
      sessionStartTime.current = new Date();
    }
  }, []);

  // Initialisation du cache de traduction
  useEffect(() => {
    initializeTranslationCache();
  }, []);

  // Configuration des callbacks Azure Speech (une seule fois)
  useEffect(() => {
    console.log('ğŸ”§ ğŸ¯ CONFIGURATION CALLBACKS AZURE SPEECH HOOK');
    
    const handleResult = async (result: any) => {
      console.log('ğŸ¤ RÃ©sultat Azure Speech:', result.text);
      
      // Protection amÃ©liorÃ©e contre duplication
      if (!result.text || result.text.trim().length < 2) {
        console.log('âš ï¸ Message ignorÃ© (vide ou trop court)');
        return;
      }

      // VÃ©rification de duplication avec tolÃ©rance temporelle (2 secondes)
      const now = Date.now();
      const timeSinceLastProcess = now - (lastProcessedTime.current || 0);
      const isSimilarText = result.text === lastProcessedText.current;
      const isRecentDuplicate = isSimilarText && timeSinceLastProcess < 2000;

      if (isProcessingRef.current) {
        console.log('âš ï¸ Message ignorÃ© (traitement en cours)');
        return;
      }

      if (isRecentDuplicate) {
        console.log('âš ï¸ Message ignorÃ© (duplication rÃ©cente)');
        return;
      }
      
      isProcessingRef.current = true;
      lastProcessedText.current = result.text;
      lastProcessedTime.current = now;
      
      setIsListening(false);
      setIsTranslating(true);

      try {
        // ğŸš€ PRIORISER LA DÃ‰TECTION AZURE, puis fallback vers notre fonction
        let detectedLanguage;
        
        // 1ï¸âƒ£ D'ABORD : Utiliser la dÃ©tection Azure (plus fiable)
        if (result.language) {
          // Convertir le code Azure (fr-FR) vers notre code (fr)
          const azureToOurCode = result.language.split('-')[0]; // fr-FR â†’ fr
          console.log(`ğŸ¯ Utilisation dÃ©tection Azure: ${result.language} â†’ ${azureToOurCode}`);
          detectedLanguage = azureToOurCode;
        } else {
          // 2ï¸âƒ£ FALLBACK : Notre fonction de dÃ©tection seulement si Azure n'a pas dÃ©tectÃ©
          console.log('ğŸ”„ Fallback vers notre dÃ©tection de langue');
          try {
            detectedLanguage = await detectLanguage(result.text);
            console.log(`ğŸ” Notre dÃ©tection: ${detectedLanguage}`);
          } catch (error) {
            console.warn('Erreur dÃ©tection langue, utilisation par dÃ©faut:', error);
            detectedLanguage = assistantLanguage; // Fallback intelligent
          }
        }
        
        console.log('ğŸ” Langue dÃ©tectÃ©e:', detectedLanguage);
        
        // DÃ©terminer qui parle
        const speaker: SpeakerRole = detectedLanguage === assistantLanguage ? 'assistant' : 'user';
        console.log('ğŸ‘¤ Locuteur dÃ©tectÃ©:', speaker);
        
        // Langue cible pour la traduction
        const targetLanguage = speaker === 'assistant' ? userLanguage : assistantLanguage;
        
        // Traduction du message avec retry
        let translatedText = result.text;
        if (detectedLanguage !== targetLanguage) {
          console.log(`ğŸ”„ Traduction: ${detectedLanguage} â†’ ${targetLanguage}`);
          
          try {
            translatedText = await translateTextForInterview(result.text, detectedLanguage, targetLanguage);
            console.log(`âœ… Traduction: "${translatedText}"`);
          } catch (error) {
            console.error('Erreur traduction, conservation du texte original:', error);
            // On garde le texte original plutÃ´t que d'Ã©chouer complÃ¨tement
          }
        }
        
        // CrÃ©er le message
        const newMessage: TranslationMessage = {
          id: crypto.randomUUID(),
          timestamp: new Date(),
          speaker: speaker,
          originalText: result.text,
          translatedText: translatedText,
          originalLanguage: detectedLanguage,
          targetLanguage: targetLanguage,
          confidence: result.confidence || 0.9
        };
        
        // Ajouter Ã  l'historique
        setMessages(prev => [...prev, newMessage]);
        
        // SynthÃ¨se vocale amÃ©liorÃ©e
        if (detectedLanguage !== targetLanguage && translatedText !== result.text) {
          await speakTranslation(translatedText, targetLanguage);
        }
        
      } catch (error) {
        console.error('âŒ Erreur traitement:', error);
        // En cas d'erreur, on peut quand mÃªme afficher le texte original
        const fallbackMessage: TranslationMessage = {
          id: crypto.randomUUID(),
          timestamp: new Date(),
          speaker: 'assistant', // Par dÃ©faut
          originalText: result.text,
          translatedText: result.text,
          originalLanguage: assistantLanguage,
          targetLanguage: assistantLanguage,
          confidence: result.confidence || 0.5
        };
        setMessages(prev => [...prev, fallbackMessage]);
      } finally {
        setIsTranslating(false);
        isProcessingRef.current = false;
      }
    };

    // ğŸš€ NOUVEAU : Gestionnaire des rÃ©sultats intermÃ©diaires pour streaming translation
    const handleInterimResult = async (interimResult: any) => {
      console.log(`ğŸš€ Streaming chunk reÃ§u: ${interimResult.wordCount} mots - "${interimResult.text}"`);
      
      // Ã‰viter le reprocessing du mÃªme chunk
      if (streamingBuffer.current === interimResult.text) {
        return;
      }
      
      streamingBuffer.current = interimResult.text;
      setIsStreaming(true);
      
      try {
        // DÃ©tection rapide de langue pour le streaming
        const detectedLanguage = await detectLanguage(interimResult.text);
        const speaker: SpeakerRole = detectedLanguage === assistantLanguage ? 'assistant' : 'user';
        const targetLanguage = speaker === 'assistant' ? userLanguage : assistantLanguage;
        
        // Traduction streaming si nÃ©cessaire
        if (detectedLanguage !== targetLanguage) {
          console.log(`ğŸš€ Streaming translation: ${detectedLanguage} â†’ ${targetLanguage}`);
          
          const streamTranslation = await translateTextForInterview(
            interimResult.text, 
            detectedLanguage, 
            targetLanguage
          );
          
          console.log(`ğŸš€ Streaming traduit: "${streamTranslation}"`);
          
          // SynthÃ¨se vocale immÃ©diate pour le streaming (optionnel)
          // await speakTranslation(streamTranslation, targetLanguage);
        }
        
      } catch (error) {
        console.warn('âš ï¸ Erreur streaming translation (non-critique):', error);
      } finally {
        setIsStreaming(false);
      }
    };

    const handleError = (error: any) => {
      console.error('âŒ Erreur Azure Speech:', error);
      setIsListening(false);
      setIsTranslating(false);
      setIsStreaming(false);
      isProcessingRef.current = false;
    };

    console.log('ğŸ”§ â• AJOUT DES LISTENERS AZURE SPEECH');
    azureSpeechService.addResultListener(handleResult);
    azureSpeechService.addInterimResultListener(handleInterimResult); // ğŸš€ NOUVEAU
    azureSpeechService.addErrorListener(handleError);
    console.log('ğŸ”§ âœ… LISTENERS AJOUTÃ‰S AVEC SUCCÃˆS');

    return () => {
      console.log('ğŸ”§ â– SUPPRESSION DES LISTENERS AZURE SPEECH');
      azureSpeechService.removeResultListener(handleResult);
      azureSpeechService.removeInterimResultListener(handleInterimResult); // ğŸš€ NOUVEAU
      azureSpeechService.removeErrorListener(handleError);
    };
  }, [assistantLanguage, userLanguage]); // DÃ©pendances minimales

  // DÃ©marrage de l'Ã©coute
  const startListening = useCallback(async () => {
    if (isListening || isTranslating) {
      console.log('âš ï¸ DÃ©jÃ  en cours...');
      return;
    }

    try {
      console.log('ğŸš€ DÃ©marrage Fast Transcription Azure Speech (latence rÃ©duite)...');
      setIsListening(true);
      
      // ğŸš€ UTILISATION FAST TRANSCRIPTION + STREAMING pour latence ultra-rÃ©duite
      await azureSpeechService.startFastRecognition({
        language: assistantLanguage, // Commencer avec la langue de l'assistant
        continuous: true,
        interimResults: true, // ğŸš€ ACTIVATION STREAMING - RÃ©sultats intermÃ©diaires pour traduction progressive
        maxDuration: 30
      });
      
      // Activer le streaming translation
      azureSpeechService.enableStreamingTranslation();
      
      // ğŸš€ ACTIVER WEBSOCKET PERSISTANT - Ã‰viter les reconnexions
      azureSpeechService.enablePersistentConnection();
    } catch (error) {
      console.error('âŒ Erreur dÃ©marrage Fast Transcription:', error);
      setIsListening(false);
    }
  }, [isListening, isTranslating, assistantLanguage]);

  // ğŸš€ MODIFIÃ‰ : Pause intelligent avec WebSocket persistant
  const stopListening = useCallback(async () => {
    if (!isListening) return;

    try {
      console.log('ğŸš€ Pause reconnaissance (WebSocket maintenu)...');
      await azureSpeechService.pauseRecognition(); // ğŸš€ NOUVEAU : Garde WebSocket ouvert
      setIsListening(false);
    } catch (error) {
      console.error('âŒ Erreur pause reconnaissance:', error);
      setIsListening(false);
    }
  }, [isListening]);

  // Fonctions simplifiÃ©es pour compatibilitÃ©
  const switchSpeaker = useCallback(() => {
    console.log('ğŸ”„ Changement de locuteur (auto-dÃ©tection active)');
  }, []);

  const pauseSession = useCallback(() => {
    stopListening();
  }, [stopListening]);

  const resumeSession = useCallback(() => {
    startListening();
  }, [startListening]);

  const endSession = useCallback(async () => {
    // ğŸš€ ArrÃªt complet avec fermeture WebSocket pour fin de session
    try {
      console.log('ğŸ Fin de session - Fermeture complÃ¨te WebSocket');
      azureSpeechService.disablePersistentConnection(); // DÃ©sactiver la persistance
      await azureSpeechService.stopRecognition(); // Fermeture complÃ¨te
      setIsListening(false);
    } catch (error) {
      console.error('âŒ Erreur fin session:', error);
    }
    
    // Calculer les stats de session
    const duration = sessionStartTime.current 
      ? Math.floor((Date.now() - sessionStartTime.current.getTime()) / 1000)
      : 0;
    
    const stats: SessionStats = {
      duration: `${Math.floor(duration / 60)}:${(duration % 60).toString().padStart(2, '0')}`,
      messageCount: messages.length,
      averageQuality: translationQuality,
      estimatedCost: (duration / 3600) * 2.8 // Estimation basique
    };
    
    setSessionStats(stats);
  }, [stopListening, messages.length, translationQuality]);

  const generateSummary = useCallback(async (): Promise<InterviewSummary | null> => {
    if (messages.length === 0) return null;

    // Simulation simple de synthÃ¨se
    const summary: InterviewSummary = {
      id: crypto.randomUUID(),
      sessionId: crypto.randomUUID(),
      generatedAt: new Date(),
      mainTopics: ['Entretien social', 'Demande d\'aide', 'Accompagnement'],
      keyDecisions: [],
      unsolvedIssues: [],
      nextSteps: ['Suivi prÃ©vu', 'Documents Ã  fournir'],
      aiRecommendations: {
        suggestedFollowUp: ['Rendez-vous de suivi'],
        relevantServices: ['Service social'],
        documentationNeeded: ['Justificatifs']
      },
      statistics: sessionStats || {
        duration: '0:00',
        messageCount: 0,
        averageQuality: 0,
        estimatedCost: 0
      }
    };

    return summary;
  }, [messages, sessionStats]);

  const exportToPDF = useCallback(async () => {
    try {
      // Export JSON simple
      const exportData = {
        title: 'Entretien AssistLux',
        date: new Date().toLocaleDateString('fr-FR'),
        languages: `${assistantLanguage.toUpperCase()} â†” ${userLanguage.toUpperCase()}`,
        messages: messages.map(msg => ({
          time: msg.timestamp.toLocaleTimeString('fr-FR'),
          speaker: msg.speaker === 'assistant' ? 'Assistant social' : 'Usager',
          original: msg.originalText,
          translated: msg.translatedText,
          language: `${msg.originalLanguage} â†’ ${msg.targetLanguage}`
        })),
        summary: await generateSummary()
      };

      const blob = new Blob([JSON.stringify(exportData, null, 2)], { type: 'application/json' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `entretien-assistlux-${new Date().toISOString().split('T')[0]}.json`;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      URL.revokeObjectURL(url);

      console.log('âœ… Export rÃ©alisÃ© avec succÃ¨s');
    } catch (error) {
      console.error('âŒ Erreur export:', error);
    }
  }, [messages, assistantLanguage, userLanguage, generateSummary]);

  const toggleAutoListenMode = useCallback(() => {
    console.log('ğŸ”„ Toggle auto-listen (fonction simplifiÃ©e)');
  }, []);

  return {
    isListening,
    isTranslating,
    isStreaming, // ğŸš€ NOUVEAU : Ã‰tat streaming translation
    translationQuality,
    messages,
    sessionStats,
    startListening,
    stopListening,
    switchSpeaker,
    pauseSession,
    resumeSession,
    endSession,
    generateSummary,
    exportToPDF,
    toggleAutoListenMode
  };
}; 